{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "816SuJk7k8Fz"
      },
      "source": [
        "\n",
        "<img align=\"left\" style=\"max-width: 200px\" src=\"https://github.com/HSG-AIML/IGARSS2023_EfficientDeepLearningEO/blob/main/01-data_fusion/banner_igarss2023.png?raw=1\">\n",
        "<img align=\"right\" style=\"max-width: 200px\" src=\"https://github.com/HSG-AIML/IGARSS2023_EfficientDeepLearningEO/blob/main/01-data_fusion/hsg_logo.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lYpB4sFpM4D"
      },
      "source": [
        "\n",
        "\n",
        "# IGARSS Tutorial *Data-efficient Deep Learning for Earth Observation* 2023\n",
        "\n",
        "## Lab - \"Data Fusion\"\n",
        "\n",
        "*Michael Mommert, Joelle Hanna, Linus Scheibenreif, Damian Borth*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jbNYaYZpM4D"
      },
      "source": [
        "In this tutorial, we will introduce the supervised learning pipeline that we will be using in the different lab sessions today and we will also discuss and implement different Data Fusion concepts to combine different data modalities from our multimodal dataset.\n",
        "\n",
        "We start by implementing a Neural Network that performs climate zone classification based on Sentinel-2 imagery. As we will build upon this model architecture in the remainder of this tutorial, we choose a U-Net segmentation model as backbone with an appropriate classfication head. Once we introduced the model setup and training pipeline, we will extend this architecture to accommodate different data fusion techniques and showcase their use and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "263NmHW9pM4E"
      },
      "source": [
        "## Tutorial Objectives\n",
        "\n",
        "After this tutorial, you should be able to:\n",
        "\n",
        "- build your own supervised learning pipeline with `pytorch`;\n",
        "- implement different early and late date fusion concepts into this pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ_lkuhgpM4F"
      },
      "source": [
        "## Content\n",
        "\n",
        "* [Setting up the environment](#setup)\n",
        "* [Data Handling](#data)\n",
        "* [Single-Modal Model Setup](#model)\n",
        "* [Training and Validation Pipeline](#train-val)\n",
        "* [Evaluation](#evaluation)\n",
        "* [Intermission: Transfer Learning](#transfer_learning)\n",
        "* [Data Fusion](#data_fusion)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_C3eI-7pM4F"
      },
      "source": [
        "\n",
        "<a id='setup'></a>\n",
        "## Setting up the environment\n",
        "\n",
        "Before we start running this Notebook, please make sure that you have a GPU available for training. If you are using Google Colab, please click `runtime`/`change runtime type` for this purpose and pick `GPU` as hardware accelerator.\n",
        "\n",
        "We're setting up our Python environment for this lab by installing and importing the necessary modules and packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wi5NrxiUYT_m",
        "outputId": "29ccaf0a-d052-4527-97eb-c3e89353fcde"
      },
      "outputs": [],
      "source": [
        "# we install a number of missing modules\n",
        "!pip install pytorch_lightning torchmetrics albumentations rasterio\n",
        "\n",
        "# system level modules for handling files and file structures\n",
        "import os\n",
        "import tarfile\n",
        "import copy\n",
        "\n",
        "# scipy ecosystem imports for numerics, data handling and plotting\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# pytorch and helper modules\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import Callback\n",
        "from torchmetrics import Accuracy\n",
        "\n",
        "# fast image augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# rasterio for reading in satellite image data\n",
        "import rasterio as rio\n",
        "from rasterio.enums import Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loq28SNYu7qH"
      },
      "source": [
        "We download the **ben-ge-800** dataset, if not yet present:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObqRQubiO_rA"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('ben-ge-800.tar.gz'):\n",
        "    !gdown 1EDm4naHNhjUWSQRluV2VXHszKiNVc6B4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvTJ9WPQOxon"
      },
      "source": [
        "**ben-ge-800** contains samples for 800 locations with co-located Sentinel-1 SAR data, Sentinel-2 multispectral data, elevation data, land-use/land-cover data, as well as environmental data. **ben-ge-800** is a subset of the much larger **ben-ge** dataset (see [https://github.com/HSG-AIML/ben-ge](https://github.com/HSG-AIML/ben-ge) for details.) We deliberately use a very small subset of **ben-ge** to enable reasonable runtimes for the examples shown in this tutorial.\n",
        "\n",
        "We extract the `ben-ge-800.tar.gz` archive. To this end, we use the [tarfile](https://docs.python.org/3.6/library/tarfile.html) module from the Python standard library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0hu6E-NPGoH"
      },
      "outputs": [],
      "source": [
        "tar_path = os.path.join('ben-ge-800.tar.gz')\n",
        "data_base_path = os.path.abspath('.')\n",
        "\n",
        "with tarfile.open(tar_path, mode='r') as tar:\n",
        "    tar.extractall(path=data_base_path)\n",
        "\n",
        "data_base_path = os.path.join(data_base_path, 'ben-ge-800')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tknjxdZDu7qK"
      },
      "source": [
        "The environment is set up and the data in place. Now we define the dataset classes and dataloaders to access the data efficiently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-le0XROa95M"
      },
      "source": [
        "<a id='data'></a>\n",
        "## Data Handling\n",
        "\n",
        "Large datasets cannot fit entirely in memory and the amount of data available to us tends to increase. This is all the more true for remote sensing data where we have multimodal data available.\n",
        "\n",
        "Ideally, you would want to load data from your local disk and train your model on GPU, all in parallel. The machinery needed to do this effectively is sophisticated and quite complicated to do yourself. Luckily, Pytorch provides a very useful tool called a `Dataloader`, which handles all of this for you. It provides, sampling, handling different batches, augmentation etc.\n",
        "\n",
        "First of all, Pytorchâ€™s dataloader must take as input a `Dataset` object.  We need to create this class, which aims to identify the main characteristics of the data you want to generate.\n",
        "A custom `Dataset` object must implement three functions: `__init__()`, `__len__()`, and `__getitem__()`.\n",
        "\n",
        "The `__init__()` function  initializes the class. This inherits properties from `torch.utils.data.Dataset`. We store important information there, such as labels or the list of  identifiers.\n",
        "Each query targets an example whose maximum index is specified in the `__len__()` function.\n",
        "\n",
        "On each request for an index of a given example, the generator executes the `__getitem__()` method to generate the data associated with it.\n",
        "\n",
        "In the following, we implement a single dataset class for all modalities in the **ben-ge** dataset, although we will only use a few of those modalities in this tutorial:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdVdNb2qP7OQ"
      },
      "outputs": [],
      "source": [
        "class BENGE(Dataset):\n",
        "    \"\"\"A dataset class implementing all ben-ge data modalities.\"\"\"\n",
        "    def __init__(self, data_dir=None,\n",
        "                 s2_bands=[\"B01\", \"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B09\", \"B11\", \"B12\"],\n",
        "                 s1_bands=[\"VH\", \"VV\"], add_dummy_band=False):\n",
        "        \"\"\"Dataset class constructor\n",
        "\n",
        "        keyword arguments:\n",
        "        data_dir -- string containing the path to the base directory of ben-ge dataset, default: ben-ge-800 directory\n",
        "        s2_bands -- list of Sentinel-2 bands to be extracted, default: all bands\n",
        "        s1_bands -- list of Senintel-1 bands to be extracted, default: all bands\n",
        "        add_dummy_band -- activate workaround to enable loading of model checkpoints pretrained on 13-band Sentinel-2 data\n",
        "\n",
        "        returns:\n",
        "        BENGE object\n",
        "        \"\"\"\n",
        "        super(BENGE, self).__init__()\n",
        "\n",
        "        # store some definitions\n",
        "        if data_dir is None:\n",
        "            self.data_dir = data_base_path\n",
        "        else:\n",
        "            self.data_dir = data_dir\n",
        "        self.s2_bands = s2_bands\n",
        "        self.s1_bands = s1_bands\n",
        "        self.augmentation = A.Compose([ToTensorV2(),])\n",
        "\n",
        "        # read in relevant data files and definitions\n",
        "        self.name = self.data_dir.split(\"/\")[-1]\n",
        "        self.meta = pd.read_csv(f\"{self.data_dir}/{self.name}_meta.csv\")\n",
        "        self.ewc_labels = pd.read_csv(f\"{self.data_dir}/{self.name}_esaworldcover.csv\")\n",
        "        self.ewc_label_names = [\"tree_cover\", \"shrubland\", \"grassland\", \"cropland\", \"built-up\",\n",
        "                                \"bare/sparse_vegetation\", \"snow_and_ice\",\"permanent_water_bodies\",\n",
        "                                \"herbaceous_wetland\", \"mangroves\",\"moss_and_lichen\"]\n",
        "        self.s2_resampling_factors = {\"B01\": 6, \"B02\": 1, \"B03\": 1, \"B04\": 1, \"B05\": 2, \"B06\": 2, \"B07\": 2, \"B08\": 1, \"B09\": 6, \"B11\": 2, \"B12\": 2, \"B8A\": 2}\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Return sample `idx` as dictionary from the dataset.\"\"\"\n",
        "        sample_info = self.meta.iloc[idx]\n",
        "        patch_id = sample_info.patch_id  # extract Sentinel-2 patch id\n",
        "        patch_id_s1 = sample_info.patch_id_s1  # extract Sentinel-1 patch id\n",
        "\n",
        "        s2 = self.load_s2(patch_id).astype(float)  # load Sentinel-2 data\n",
        "        s2 = np.moveaxis(s2, 0, -1)\n",
        "        if self.s1_bands:\n",
        "            s1 = self.load_s1(patch_id_s1).astype(float)  # load Sentinel-1 data\n",
        "            s1 = (np.clip(s1, a_min=-25, a_max=0) + 25) / 25\n",
        "        else:\n",
        "            s1 = None\n",
        "\n",
        "        # extract top land-use/land-cover label\n",
        "        label = np.argmax(self.ewc_labels[self.ewc_labels.patch_id == patch_id][self.ewc_label_names])\n",
        "\n",
        "        # land-use/land-cover map data\n",
        "        ewc_mask = self.load_ewc(patch_id).astype(float)\n",
        "        ewc_mask[ewc_mask == 100] = 110\n",
        "        ewc_mask[ewc_mask == 95] = 100\n",
        "        ewc_mask = ewc_mask / 10 - 1 # transform to scale [0, 11]\n",
        "        ewc_mask = np.moveaxis(ewc_mask, 0, -1)\n",
        "\n",
        "        augmented = self.augmentation(image=s2, mask=ewc_mask)  # generate augmented data\n",
        "\n",
        "        # reassign and normalize augmented Sentinel-2 data\n",
        "        s2 = torch.clip(augmented[\"image\"].float() / 10000, 0, 1)\n",
        "\n",
        "        # reassign augmented land-use/land-cover data\n",
        "        ewc_mask = augmented[\"mask\"]\n",
        "\n",
        "        season = sample_info[\"season_s2\"] # seasonal data\n",
        "        climatezone = {0: 0, 7: 1, 8: 2, 9: 3, 14: 4, 15: 5, 16: 6, 18: 7,\n",
        "                       25: 8, 26: 9, 27: 10, 29: 11}[sample_info[\"climatezone\"]]  # climatezone data\n",
        "\n",
        "        # create sample dictionary containing all the data\n",
        "        sample = {\n",
        "            \"s2\": s2,\n",
        "            \"lulc_mask\": ewc_mask,\n",
        "            \"patch_id\": patch_id,\n",
        "            \"lon\": sample_info.lon.item(),\n",
        "            \"lat\": sample_info.lat.item(),\n",
        "            \"lulc_top\": torch.from_numpy(np.array([label.copy()], dtype=float)),\n",
        "            \"season\": season,\n",
        "            \"climatezone\": climatezone\n",
        "            }\n",
        "\n",
        "        if s1 is not None:  # add Sentinel-1 data, if generated\n",
        "            sample[\"s1\"] = torch.tensor(s1).float()\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return length of this dataset.\"\"\"\n",
        "        return self.meta.shape[0]\n",
        "\n",
        "    def load_s2(self, patch_id):\n",
        "        \"\"\"Helper function to load Sentinel-2 data for a given `patch_id`.\"\"\"\n",
        "        img = []\n",
        "\n",
        "        for band in self.s2_bands:\n",
        "            upscale_factor = self.s2_resampling_factors.get(band)\n",
        "            # read corresponding data file and upsample based on resampling factor\n",
        "            with rio.open(f\"{self.data_dir}/sentinel-2/{patch_id}/{patch_id}_{band}.tif\") as d:\n",
        "                data = d.read(\n",
        "                out_shape=(\n",
        "                    d.count,\n",
        "                    int(d.height * upscale_factor),\n",
        "                    int(d.width * upscale_factor)\n",
        "                ),\n",
        "                resampling=Resampling.bilinear\n",
        "            )\n",
        "            img.append(data)\n",
        "\n",
        "        img = np.concatenate(img)\n",
        "        return img\n",
        "\n",
        "    def load_s1(self, s1_patch_id):\n",
        "        \"\"\"Helper function to load Sentinel-1 data for a given `patch_id`.\"\"\"\n",
        "        img = []\n",
        "\n",
        "        for band in self.s1_bands:\n",
        "            # read corresponding data file\n",
        "            with rio.open(f\"{self.data_dir}/sentinel-1/{s1_patch_id}/{s1_patch_id}_{band}.tif\") as d:\n",
        "                data = d.read()\n",
        "                img.append(data)\n",
        "\n",
        "        img = np.concatenate(img)\n",
        "        return img\n",
        "\n",
        "    def load_ewc(self, patch_id):\n",
        "        \"\"\"Helper function to load ESAWorldCover data for a given `patch_id`.\"\"\"\n",
        "        with rio.open(f\"{self.data_dir}/esaworldcover/{patch_id}_esaworldcover.tif\") as d:\n",
        "            data = d.read()\n",
        "\n",
        "        return data\n",
        "\n",
        "    def visualize_observation(self, idx):\n",
        "        \"\"\"Visualize data sample `idx`.\"\"\"\n",
        "\n",
        "        # define ESA WorldCover colormap\n",
        "        COLOR_CATEGORIES = [\n",
        "            (0, 100, 0),\n",
        "            (255, 187, 34),\n",
        "            (255, 255, 76),\n",
        "            (240, 150, 255),\n",
        "            (250, 0, 0),\n",
        "            (180, 180, 180),\n",
        "            (240, 240, 240),\n",
        "            (0, 100, 200),\n",
        "            (0, 150, 160),\n",
        "            (0, 207, 117),\n",
        "            (250, 230, 160)]\n",
        "        cmap_all = mpl.colors.ListedColormap(np.array(COLOR_CATEGORIES)/255.)\n",
        "\n",
        "        # read sample\n",
        "        sample = self.__getitem__(idx)\n",
        "        image = sample.get(\"s2\").squeeze()\n",
        "        mask = sample.get(\"lulc_mask\")\n",
        "\n",
        "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        img_rgb = image[[3, 2, 1], :, :]\n",
        "        img_rgb = np.transpose(img_rgb, (1, 2, 0))\n",
        "        scaled_img_rgb = (img_rgb - np.min(img_rgb.numpy(), axis=(0,1)))/(np.max(img_rgb.numpy(), axis=(0,1))-np.min(img_rgb.numpy(), axis=(0,1)))\n",
        "\n",
        "        axs[0].imshow(np.clip(1.5*scaled_img_rgb + 0.1, 0, 1))\n",
        "        axs[0].set_title(\"Sentinel-2 RGB\")\n",
        "        axs[0].axis('off')\n",
        "\n",
        "        mask = mask.squeeze()\n",
        "\n",
        "        axs[1].imshow(mask, cmap=cmap_all, vmin=0, vmax=11, interpolation=None)\n",
        "        axs[1].set_title(\" Climate Zone: {} \\n Season: {} \\n Segmentation Mask\".format(sample.get(\"climatezone\"), sample.get(\"season\")))\n",
        "        axs[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ8_dYPBu7qM"
      },
      "source": [
        "\n",
        "\n",
        "Now that the `BENGE` dataset class is created, we will encapsulate everything in a *Pytorch Lightning* data module, takes care of common data processing and handling steps in *PyTorch*, such as creating `DataLoader`s. A `DataLoader` turns a number of samples (defined by `batch_size`) into a mini-batch for efficient training. By using *Lightning* data modules, we do not have to worry much about `DataLoader`s."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5S8j7-0Au7qM"
      },
      "outputs": [],
      "source": [
        "class BENGEDataModule(pl.LightningDataModule):\n",
        "    \"\"\"Pytorch Lightning data module class for ben-ge.\"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"BENGEDataModule constructor.\"\"\"\n",
        "        super(BENGEDataModule).__init__()\n",
        "\n",
        "    def prepare_data(self):\n",
        "        \"\"\"Method to prepare data.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def setup(self, data_dir, train_batch_size, eval_batch_size):\n",
        "        \"\"\"Method to setup dataset and corresponding splits.\"\"\"\n",
        "        dataset = BENGE(data_dir)\n",
        "        assert len(dataset) == 800  # check dataset size\n",
        "        self.trainset, self.valset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), int(len(dataset)*0.2)])\n",
        "        self.valset, self.testset = torch.utils.data.random_split(self.valset, [int(len(dataset)*0.1), int(len(dataset)*0.1)])\n",
        "\n",
        "        self.train_bs = train_batch_size\n",
        "        self.eval_bs = eval_batch_size\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        \"\"\"Return training dataset loader.\"\"\"\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.trainset, batch_size=self.train_bs, num_workers=4, pin_memory=True\n",
        "        )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        \"\"\"Return validation dataset loader.\"\"\"\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.valset, batch_size=self.eval_bs, num_workers=4, pin_memory=True\n",
        "        )\n",
        "    def test_dataloader(self):\n",
        "        \"\"\"Return test dataset loader.\"\"\"\n",
        "        return torch.utils.data.DataLoader(\n",
        "            self.testset, batch_size=self.eval_bs, num_workers=4, pin_memory=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOjFUrrAu7qN"
      },
      "source": [
        "Now we can instantiate the data module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUXSecoJu7qN"
      },
      "outputs": [],
      "source": [
        "# we set the random seed value...\n",
        "seed = 42\n",
        "pl.seed_everything(seed)\n",
        "\n",
        "train_batch_size = 32\n",
        "eval_batch_size = 32\n",
        "\n",
        "# ... and initialize the data module\n",
        "data_module = BENGEDataModule()\n",
        "data_module.setup(\"./ben-ge-800\", train_batch_size, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-du-uGoWsgH"
      },
      "source": [
        "And, finally, we can visualise some observations using the method *visualize_observation()*. Data visualization is the simplest part, but also the most important, to understand the task, and improve the performance of the model. It is important to check a couple of samples, making sure that the groundtruth you're working with is consistent.\n",
        "\n",
        "From the data module, we can easily access samples in the training dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqON7lvHVEJ0"
      },
      "outputs": [],
      "source": [
        "data_module.trainset.dataset.visualize_observation(100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_bVEfRpM4W"
      },
      "source": [
        "<a id='model'></a>\n",
        "## Single-Modal Model Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOK06D2caPjB"
      },
      "source": [
        "In this tutorial, we will use a U-Net ([Ronneberger et al. (2015)](https://arxiv.org/abs/1505.04597) as the shared backbone. As a Fully Convolutional Neural Network, it is predestined to work with image-like data and makes no assumption on the size of the input data (height and width). The architecture of U-Net is composed of two \"paths\":\n",
        "- The first one is the contracting path, also called the *encoder*. It is used to capture the context of an image. It is in fact a group of convolution layers and max pooling layers allowing to create a feature map of an image and to reduce its size in order to reduce the number of network parameters.\n",
        "- The second path is the symmetric expanding, also called *decoder*.\n",
        "\n",
        "Although conceived as a segmentation model, we will use it across a wide range of downstream tasks, such as segmentation, classification and regression. As a side note: the U-Net could be easily replaced with most other Deep Learning models (depending on the downstream task).\n",
        "For each downstream task, we will append to the decoder a separate head that is related to the corresponding task.\n",
        "\n",
        "We build a simple U-Net implementation (following [this implementation](https://github.com/milesial/Pytorch-UNet)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahvl1t76adqH"
      },
      "outputs": [],
      "source": [
        "# Define the convolution block\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"\n",
        "    The DoubleConv object is composed of two successive blocks of convolutional layers, batch normalization and ReLU.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "\n",
        "        # Create a sequential module.\n",
        "        # nn.Sequential is a module inside which you can put other modules that will be applied one after the other.\n",
        "        self.double_conv = nn.Sequential(\n",
        "            # First convolutional layer\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "\n",
        "            # First batchnormalization\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "\n",
        "            # First ReLU activation function\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Second convolutional layer\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "\n",
        "            # Second batchnormalization\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "\n",
        "            # Second ReLU activation function\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "# Define the downsampling block\n",
        "class Down(nn.Module):\n",
        "    \"\"\"\n",
        "    The Down object is composed of a maxpooling layer followed by the DoubleConv block defined above.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        # Create a sequential module.\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            # 2D max pooling layer with a kernel size of 2 (meaning spatial dimension will be divided by two)\n",
        "            nn.MaxPool2d(2),\n",
        "\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "# Create the upsampling block\n",
        "class Up(nn.Module):\n",
        "    \"\"\"\n",
        "    The Up object is composed of an upsampling layer (bilinear interpolation) followed by the DoubleConv block defined above.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        # upsampling layer with a scale factor of 2 (meaning spatial dimension will be multiplied by two)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "        self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNetBackbone(nn.Module):\n",
        "    \"\"\"U-Net implementation based on the previously defined building blocks.\"\"\"\n",
        "    def __init__(self, n_channels):\n",
        "        super(UNetBackbone, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor)\n",
        "        self.up2 = Up(512, 256 // factor)\n",
        "        self.up3 = Up(256, 128 // factor)\n",
        "        self.up4 = Up(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTdoK7TiXQkJ"
      },
      "source": [
        "Please note that the output of the U-Net will be a feature map of the same size (width x height) as the input image and with 64 output channels (this is a design choice; the number of output channels will be reduced in the head, depending on the downstream task).\n",
        "\n",
        "In this lab, we will focus on the **classification of climate zones** as our downstream task (other tasks will follow in the multitask learning lab). Therefore, we will also define a classification head that we can use in combination with our U-Net implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aiJpdz4cRm5"
      },
      "outputs": [],
      "source": [
        "class MulticlassClassificationHead(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_class):\n",
        "        super(MulticlassClassificationHead, self).__init__()\n",
        "        self.out_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        self.fc = nn.Sequential(nn.Dropout(p=0.5), nn.Linear(120 * 120, num_class))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.out_conv(x)\n",
        "        x2 = x1.view(-1, 120 * 120)\n",
        "        x_out = self.fc(x2)\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYvMMnVRu7qQ"
      },
      "source": [
        "This head is applicable to a multi-class classification problem, as we have it in the case of climate zone classification (12 different classes in this dataset). Architecture-wise, the head consists of a single convolutional layer and a single linear layer in combination with dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGO7OlosYA44"
      },
      "source": [
        "And now we plug everything together:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaJLON_ckFW_"
      },
      "outputs": [],
      "source": [
        "class ClassificationUNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes):\n",
        "        super(ClassificationUNet, self).__init__()\n",
        "        self.backbone = UNetBackbone(n_channels)\n",
        "        self.out = MulticlassClassificationHead(64, 1, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x_out = self.out(x)\n",
        "\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEHOWh3ju7qR"
      },
      "source": [
        "This concludes our model implementation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy_LH3aUpM4Z"
      },
      "source": [
        "<a id='train-val'></a>\n",
        "### Training and Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki5CJB_fu7qR"
      },
      "source": [
        "First of all, let's verify if a GPU is available on our compute machine. If not, the CPU will be used instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xb_5oxnbcId"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Device used: {}'.format(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl4509B-8kIZ"
      },
      "source": [
        "Now we can define the *Pytorch Lightning* trainer class, which takes care of all aspects related to the training of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn8Kiqd-iR3l"
      },
      "outputs": [],
      "source": [
        "class MetricTracker(Callback):\n",
        "    \"\"\"This class tracks and enables access to metrics generated during the training process.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.collection = []\n",
        "\n",
        "    def on_validation_epoch_end(self, trainer, module):\n",
        "        elogs = copy.deepcopy(trainer.callback_metrics)\n",
        "        self.collection.append(elogs)\n",
        "\n",
        "\n",
        "class ClassificationUNetTrainer(pl.LightningModule):\n",
        "    \"\"\"This class encapsulates the entire training pipeline for our classification task.\"\"\"\n",
        "    def __init__(self, model, criterion, optimizer, scheduler):\n",
        "        \"\"\"Constructor for our trainer class.\n",
        "\n",
        "        positional arguments:\n",
        "        model -- model instance\n",
        "        criterion -- loss function instance\n",
        "        optimizer -- optimizer instance\n",
        "\n",
        "        keyword arguments:\n",
        "        scheduler -- learning rate scheduler instance, default: None\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "\n",
        "        # Train and Validation Metrics:\n",
        "        self.train_metric = Accuracy(task=\"multiclass\", num_classes=12)\n",
        "        self.val_metric = Accuracy(task=\"multiclass\", num_classes=12)\n",
        "        self.test_metric = Accuracy(task=\"multiclass\", num_classes=12)\n",
        "\n",
        "    def forward(self, img):\n",
        "        \"\"\"Forward pass method.\"\"\"\n",
        "        return self.model(img)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"\"\"Optimizer configuration method.\"\"\"\n",
        "        if not self.scheduler is None:\n",
        "            lr_scheduler_config = {\n",
        "                \"scheduler\": self.scheduler,\n",
        "                \"interval\": \"epoch\",\n",
        "                \"frequency\": 1,\n",
        "                \"monitor\": \"val_loss\",\n",
        "                \"strict\": True,\n",
        "                \"name\": None,\n",
        "            }\n",
        "            return {\"optimizer\": self.optimizer, \"lr_scheduler\": lr_scheduler_config}\n",
        "        else:\n",
        "            return self.optimizer\n",
        "\n",
        "    def loss(self, pred, target):\n",
        "        \"\"\"Loss computation method.\"\"\"\n",
        "        return self.criterion(pred, target)\n",
        "\n",
        "    def get_target(self, batch):\n",
        "        \"\"\"Retrieve target variable for climate zone classification.\"\"\"\n",
        "        y = batch[\"climatezone\"].squeeze().long()\n",
        "        return y\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        \"\"\"Training step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(train_batch)  # retrieve target\n",
        "        data = train_batch[\"s2\"].float()  # retrieve input\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        train_metric = self.train_metric(output, y)\n",
        "        train_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"train_loss\": train_loss.item(),\n",
        "            \"train_metric\": train_metric.item(),\n",
        "        }\n",
        "\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        \"\"\"Validation step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(val_batch)\n",
        "        data = val_batch[\"s2\"].float()\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        val_metric = self.val_metric(output, y)\n",
        "        val_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"val_loss\": val_loss.item(),\n",
        "            \"val_metric\": val_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        \"\"\"Test step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(test_batch)\n",
        "        data = test_batch[\"s2\"].float()\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        test_metric = self.test_metric(output, y)\n",
        "        test_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"test_loss\": test_loss.item(),\n",
        "            \"test_metric\": test_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return test_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5CQZ3jzpM4a"
      },
      "source": [
        "Our model is now ready to be trained. The following cell defines the missing components like the Loss function, the optimizer and learning rate scheduler and instantiates the trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B36iygw2LxO3"
      },
      "outputs": [],
      "source": [
        "model = ClassificationUNet(n_channels=12, n_classes=12)  # we instantiate the model\n",
        "# n_channels=12 since we have 12 channel Sentinel-2 data\n",
        "# n_classes=12 since we have 12 different climate zone classes\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()  # we use cross entropy loss\n",
        "\n",
        "learning_rate = 0.0001  # we set the learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)  # we use stochastic gradient descent as our optimizer\n",
        "\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)  # we use a Cosine annealing learning rate schedulder\n",
        "\n",
        "model_trainer = ClassificationUNetTrainer(model, criterion, optimizer, scheduler)  # we instantiate the trainer\n",
        "\n",
        "metrics_class = MetricTracker()  # we instantiate the metrics tracker\n",
        "\n",
        "# ... and finally, we instantiate the trainer\n",
        "trainer = pl.Trainer(\n",
        "    accelerator='cuda' if 'cuda' in str(device) else 'cpu',\n",
        "    devices=1,\n",
        "    max_epochs=20,\n",
        "    log_every_n_steps=1,\n",
        "    accumulate_grad_batches=1,\n",
        "    callbacks=([metrics_class]),\n",
        "    default_root_dir = \"models/ClassificationUNetClimatezone/\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjfjxm5wu7qU"
      },
      "source": [
        "And now, we finally start the training process (we will only train the model for a small number of epochs in this tutorial):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNiNStv-uZsc"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model_trainer, data_module.train_dataloader(), data_module.val_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0W68AszYff"
      },
      "source": [
        "We can plot and compare the different metrics that were collect during training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osoEDW3rA735"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
        "val_loss = [el['val_loss_epoch'].cpu() for el in metrics_class.collection[1:]]\n",
        "train_loss = [el['train_loss'].cpu() for el in metrics_class.collection[1:]]\n",
        "\n",
        "val_iou = [el['val_metric_epoch'].cpu() for el in metrics_class.collection[1:]]\n",
        "train_iou = [el['train_metric'].cpu() for el in metrics_class.collection[1:]]\n",
        "\n",
        "axes[0].plot(val_loss, label='val')\n",
        "axes[0].plot(train_loss, label='train')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_title('Losses')\n",
        "axes[0].legend()\n",
        "\n",
        "axes[1].plot(val_iou, label='val')\n",
        "axes[1].plot(train_iou, label='train')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_title('Accuracies')\n",
        "axes[1].legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZyU5I1h0vZi"
      },
      "source": [
        "The model is definitely learning something. We could now **tune the model hyperparameters** (e.g., learning rate) and architecture based on the validation loss and metric. We'll skip this process for this tutorial to keep the labs reasonably short.\n",
        "\n",
        "<a id='evaluation'></a>\n",
        "### Evaluation\n",
        "\n",
        "Let's evaluate the trained model on the test dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFXFNxN3MBeK"
      },
      "outputs": [],
      "source": [
        "trainer.test(model_trainer, dataloaders=data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCfjknzr8CoB"
      },
      "source": [
        "The resulting test metrics are very similar to the metrics based on the validation dataset, indicating that the model is not yet overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeE_2-hg8YRN"
      },
      "source": [
        "## Intermission: Transfer Learning\n",
        "\n",
        "We briefly talked about Transfer Learning. The idea here is to train a model that is not randomly initialized, but instead to train a model that has been previously trained (pre-trained) on a similar dataset and/or task. We briefly introduce this concept here, since we will take advantage of it in the later lab sessions.\n",
        "\n",
        "In the end, all you need to do is to load a pre-trained model checkpoint. Here's how to load a pre-trained model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfDboMnQMNJU",
        "tags": []
      },
      "outputs": [],
      "source": [
        "best_model = ClassificationUNet(n_channels=12, n_classes=12)  # instantiate a new model\n",
        "\n",
        "# download model checkpoint if not yet present\n",
        "if not os.path.exists('ClassificationUNet.ckpt'):\n",
        "    !gdown 15vs4NP9_5Lm5r7Ed_gx7pPgr1J0irtfL\n",
        "\n",
        "# load checkpoint\n",
        "if 'cuda' in str(device):\n",
        "    state_dict = torch.load(\"ClassificationUNet.ckpt\")[\"state_dict\"]\n",
        "else:\n",
        "    state_dict = torch.load(\"ClassificationUNet.ckpt\", map_location=torch.device('cpu'))[\"state_dict\"]\n",
        "\n",
        "best_model.load_state_dict({k.replace(\"model.\", \"\") : v for k,v in state_dict.items()})\n",
        "best_model.to(device);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFpRyAqWeJMp"
      },
      "source": [
        "Now we can use this loaded model and evaluate it over the test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNeTUjxrfVGq"
      },
      "outputs": [],
      "source": [
        "best_model_trainer = ClassificationUNetTrainer(best_model, criterion, optimizer, scheduler)\n",
        "best_trainer = pl.Trainer(\n",
        "    accelerator='cuda' if 'cuda' in str(device) else 'cpu',\n",
        "    devices=1,\n",
        "    max_epochs=20,\n",
        "    log_every_n_steps=1,\n",
        "    accumulate_grad_batches=1,\n",
        "    callbacks=([metrics_class])\n",
        ")\n",
        "\n",
        "best_trainer.test(best_model_trainer, dataloaders=data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5vCOCe_9SQO"
      },
      "source": [
        "The measured accuracy on the test split is much better than before (33%). This is the result of the additional training: this model was trained for 20 epochs compared to the 5 epochs of the previous model.\n",
        "\n",
        "In case you are wondering how to save a model checkpoint: you have been doing it all the time. After each training epoch, *PyTorch Lightning* will write the most recent checkpoint to file if you provide a corresonding path string to the `default_root_dir` key in your `Trainer` instance (see above)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNK0H-XCgTpo"
      },
      "source": [
        "## Data Fusion\n",
        "\n",
        "\n",
        "In the remainder of this lab, we will experiment with some Data Fusion concepts. Namely, we will implement **Early Fusion** and **Late Fusion**. We will also make use of different data modalities to showcase how different data types can be utilized in this process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRe7sBPJhc5J"
      },
      "source": [
        "### Early Fusion\n",
        "\n",
        "In Early Fusion, two or more data modalities are combined before they enter the backbone, which in our case is our U-Net model.\n",
        "\n",
        "In the simplest case, both modalities have the same dimensionality and shape. The best example for this case is the fusion of Sentinel-2 and Sentinel-2 data.\n",
        "\n",
        "#### Sentinel-1/2 Data Fusion\n",
        "\n",
        "In the following example, we will perform Early Fusion of Sentinel-2 and Sentinel-2 data. Both modalities are available from our dataset class, have the same dimensionality and shape. There are two things we have to do:\n",
        "First, we have to change the number of input channels of our model from 12 to 14 (12 Sentinel-2 + 2 Sentinel-1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WydlkHLqt26"
      },
      "outputs": [],
      "source": [
        "model_ef = ClassificationUNet(n_channels=14, n_classes=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csvan9X8qr6M"
      },
      "source": [
        "Second, we have to change the different `step` methods in our `ClassificationUNetTrainer` class to perform the concatenation of the data. Note that we will inherit our new class from `ClassficationUNetTrainer` and only change the relevant methods:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJRLEl4nhb-o"
      },
      "outputs": [],
      "source": [
        "class S12EFClassificationUNetTrainer(ClassificationUNetTrainer):\n",
        "    \"\"\"This class encapsulates the entire training pipeline for our\n",
        "    Sentinel-1/2 early fusion model.\"\"\"\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        \"\"\"Training step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(train_batch)\n",
        "        data_s2 = train_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = train_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data = torch.cat([data_s2, data_s1], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        train_metric = self.train_metric(output, y)\n",
        "        train_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"train_loss\": train_loss.item(),\n",
        "            \"train_metric\": train_metric.item(),\n",
        "        }\n",
        "\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        \"\"\"Validation step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(val_batch)\n",
        "        data_s2 = val_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = val_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data = torch.cat([data_s2, data_s1], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        val_metric = self.val_metric(output, y)\n",
        "        val_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"val_loss\": val_loss.item(),\n",
        "            \"val_metric\": val_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        \"\"\"Test step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(test_batch)\n",
        "        data_s2 = test_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = test_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data = torch.cat([data_s2, data_s1], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        test_metric = self.test_metric(output, y)\n",
        "        test_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"test_loss\": test_loss.item(),\n",
        "            \"test_metric\": test_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vpvfuC1j6G4"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model_ef.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "model_trainer_ef = S12EFClassificationUNetTrainer(model_ef, criterion, optimizer, scheduler)\n",
        "metrics_class_ef = MetricTracker()\n",
        "\n",
        "trainer_ef = pl.Trainer(\n",
        "    accelerator='cuda' if 'cuda' in str(device) else 'cpu',\n",
        "    devices=1,\n",
        "    max_epochs=5,\n",
        "    log_every_n_steps=1,\n",
        "    accumulate_grad_batches=1,\n",
        "    callbacks=([metrics_class_ef]),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXCkzp3ak2Mx"
      },
      "outputs": [],
      "source": [
        "trainer_ef.fit(model_trainer_ef, data_module.train_dataloader(), data_module.val_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjooYqSrqyK"
      },
      "source": [
        "That worked, how does the result compare to our Sentinel-2-only baseline model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwdDbkh4k6_8"
      },
      "outputs": [],
      "source": [
        "trainer_ef.test(model_trainer_ef, dataloaders=data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRUIIbNLr2Wp"
      },
      "source": [
        "Since this model performs the same task that we used before (predict climate zone), we can compare the performance directly to the metrics that we derived above. For the same training duration (5 epochs), we previously achieved an accuracy of 33% by only training on the 12 Sentinel-2 bands. Now, by performing early data fusion on Sentinel-1 and Sentinel-2, we achieve an accuracy of 40%.\n",
        "\n",
        "**This is great! The combination of Sentinel-1 and Sentinel-2 data indeed improves the performance of the model!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwLWZG07sQa8"
      },
      "source": [
        "#### Sentinel-1/2 + Season Data Fusion\n",
        "\n",
        "Now that was easy. What if the data modalities that we would like to fuse are not directly compatible? Consider the case that we would like to add the seasonality data to the Sentinel-1/2 data. In this case, we could use a so-called **blow-up** patch.\n",
        "\n",
        "This patch would have to be generated in the `step` methods, too:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evgoQBPir0f8"
      },
      "outputs": [],
      "source": [
        "class S12seasonEFClassificationUNetTrainer(ClassificationUNetTrainer):\n",
        "    \"\"\"This class encapsulates the entire training pipeline for our\n",
        "    Sentinel-1/2+season early fusion model.\"\"\"\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        \"\"\"Training step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(train_batch)\n",
        "        data_s2 = train_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = train_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data_season = (torch.ones(len(train_batch['s2']), 1, 120, 120).to(device) *\n",
        "                       train_batch[\"season\"].view(-1, 1, 1, 1)).float()  # we create a blow-up patch for seasonality data\n",
        "        data = torch.cat([data_s2, data_s1, data_season], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        train_metric = self.train_metric(output, y)\n",
        "        train_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"train_loss\": train_loss.item(),\n",
        "            \"train_metric\": train_metric.item(),\n",
        "        }\n",
        "\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "\n",
        "        return train_loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        \"\"\"Validation step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(val_batch)\n",
        "        data_s2 = val_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = val_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data_season = (torch.ones(len(val_batch['s2']), 1, 120, 120).to(device) *\n",
        "                       val_batch[\"season\"].view(-1, 1, 1, 1)).float()  # we create a blow-up patch for seasonality data\n",
        "        data = torch.cat([data_s2, data_s1, data_season], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        val_metric = self.val_metric(output, y)\n",
        "        val_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"val_loss\": val_loss.item(),\n",
        "            \"val_metric\": val_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "    def test_step(self, test_batch, batch_idx):\n",
        "        \"\"\"Test step definition for mini-batch `train_batch` with index `batch_idx`.\"\"\"\n",
        "        y = self.get_target(test_batch)\n",
        "        data_s2 = test_batch[\"s2\"].float()  # retrieve S2 data\n",
        "        data_s1 = test_batch[\"s1\"].float()  # retrieve S1 data\n",
        "        data_season = (torch.ones(len(test_batch['s2']), 1, 120, 120).to(device) *\n",
        "                       test_batch[\"season\"].view(-1, 1, 1, 1)).float()  # we create a blow-up patch for seasonality data\n",
        "        data = torch.cat([data_s2, data_s1, data_season], dim=1)  # concanenate data along channel dimension\n",
        "\n",
        "        output = self.forward(data)\n",
        "\n",
        "        test_metric = self.test_metric(output, y)\n",
        "        test_loss = self.loss(output, y)\n",
        "\n",
        "        stats = {\n",
        "            \"test_loss\": test_loss.item(),\n",
        "            \"test_metric\": test_metric.item(),\n",
        "        }\n",
        "        self.log_dict(stats, batch_size=data.shape[0], on_step=False, on_epoch=True, prog_bar=True)\n",
        "        return test_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TMuZoQJuDLu"
      },
      "source": [
        "... and we have to increase the number of input channels to 15:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6pJFT5it049"
      },
      "outputs": [],
      "source": [
        "model_ef2 = ClassificationUNet(n_channels=15, n_classes=12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bjCk0bGuKHV"
      },
      "source": [
        "We reinitialize everything and start the training process:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guGk8OO0uJBu"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.SGD(model_ef2.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "model_trainer_ef2 = S12seasonEFClassificationUNetTrainer(model_ef2, criterion, optimizer, scheduler)\n",
        "metrics_class_ef2 = MetricTracker()\n",
        "\n",
        "trainer_ef2 = pl.Trainer(\n",
        "    accelerator='cuda' if 'cuda' in str(device) else 'cpu',\n",
        "    devices=1,\n",
        "    max_epochs=5,\n",
        "    log_every_n_steps=1,\n",
        "    accumulate_grad_batches=1,\n",
        "    callbacks=([metrics_class_ef]),\n",
        ")\n",
        "\n",
        "trainer_ef2.fit(model_trainer_ef2, data_module.train_dataloader(), data_module.val_dataloader())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFpStHePu0pW"
      },
      "outputs": [],
      "source": [
        "trainer_ef2.test(model_trainer_ef2, dataloaders=data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YQEBCRXmD5C"
      },
      "source": [
        "Again, we can directly compare the resulting metrics. The test split accuracy is 32% in this case, which is even lower than the 33% achieved by our Sentinel-2-only baseline model.\n",
        "\n",
        "How is this possible? Maybe the seasonality data is simply not useful for this task, or might actually be harmful for the prediction of climate zones. It might also be related to the dataset being too small.\n",
        "\n",
        "The important lesson here is that **blindly combining data modalities is not always beneficial**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZxIaqKAp4A6"
      },
      "source": [
        "### Late Fusion\n",
        "\n",
        "Now we try a different approach to data fusion: Late Fusion. In Late Fusion, we use a separate backbone for each data modality and then combine the representations coming from each backbone before they enter the head.\n",
        "\n",
        "The intuition behind this is that each backbone can focus on a single data modality, hopefully learning richer representations than a shared backbone.\n",
        "\n",
        "We will implement Late Fusion again on the task of climate zone prediction and fuse Sentinel-1 and Sentinel-2 data. For this purpose, we have to build a new model architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38_y0_hZfBHO"
      },
      "outputs": [],
      "source": [
        "class LFClassificationUNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(LFClassificationUNet, self).__init__()\n",
        "        self.backbone_s1 = UNetBackbone(2)   # Sentinel-1 backbone (2 input channels)\n",
        "        self.backbone_s2 = UNetBackbone(12)  # Sentinel-2 backbone (12 input channels)\n",
        "\n",
        "        self.head = MulticlassClassificationHead(128, 1, n_classes)\n",
        "        # the classification head now has 128 channels, which is the concatenation of the\n",
        "        # two outputs from the backbones\n",
        "\n",
        "    def forward(self, x):\n",
        "        # we assume that `x` is of shape (batch_size, 14, 120, 120) where\n",
        "        # axis=1 is split in such a way that [0:13] contains s2 data and\n",
        "        # [12:] contains the two s1 bands\n",
        "\n",
        "        z_s1 = self.backbone_s1(x[:,12:,:,:])\n",
        "        z_s2 = self.backbone_s2(x[:,:12,:,:])\n",
        "\n",
        "        z = torch.cat((z_s1, z_s2), dim=1)\n",
        "\n",
        "        return self.head(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMPZrwq8r3-M"
      },
      "source": [
        "Since we assume that the input data are a concatenation of Sentinel-2 and Sentinel-1 data, we can simply reuse our first Early Fusion trainer module, `S12EFClassificationUNetTrainer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GAGCu3fp0MU"
      },
      "outputs": [],
      "source": [
        "model_lf = LFClassificationUNet(n_classes=12)\n",
        "\n",
        "optimizer = optim.SGD(model_lf.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n",
        "model_trainer_lf = S12EFClassificationUNetTrainer(model_lf, criterion, optimizer, scheduler)\n",
        "metrics_class_lf = MetricTracker()\n",
        "\n",
        "trainer_lf = pl.Trainer(\n",
        "    accelerator='cuda' if 'cuda' in str(device) else 'cpu',\n",
        "    devices=1,\n",
        "    max_epochs=5,\n",
        "    log_every_n_steps=1,\n",
        "    accumulate_grad_batches=1,\n",
        "    callbacks=([metrics_class_lf]),\n",
        ")\n",
        "\n",
        "trainer_lf.fit(model_trainer_lf, data_module.train_dataloader(), data_module.val_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0aV349SAPTi"
      },
      "source": [
        "The training process has concluded, so let's have a look at the test split results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYpFWaSorTXe"
      },
      "outputs": [],
      "source": [
        "trainer_lf.test(model_trainer_lf, dataloaders=data_module.test_dataloader())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RBTVdKFuTgw"
      },
      "source": [
        "With Late Fusion of Sentinel-1 and Sentinel-2, we obtain a test split accuracy of 52%. Keep in mind that this approach uses the same combination of data modalities as our first Early Fusion approach, which resulted in a test split accuracy of 40% after the same number of epochs.\n",
        "\n",
        "Does that mean that Late Fusion always performs better than Early Fusion? Not necessarily, but be aware that, since we use two identical backbones in this implementation, this model architecture therefore also has about twice as many parameters as the Early Fusion approach. The larger capacity of this model definitely has a beneficial effect on the model performance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcJJrLU7I69Q"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this lab we introduced the general supervised learning pipeline, which we will use throughout this tutorial.\n",
        "\n",
        "We also introduced two flavors of Data Fusion: Early Fusion and Late Fusion.\n",
        "\n",
        "In Early Fusion, different data modalities are fused before they are run through the Deep Learning model.\n",
        "\n",
        "In Late Fusion, each data modality is run through a separate backbone model, before the fusion of both outputs is run through the model head.\n",
        "\n",
        "In general, it is hard to say which flavor works better. It depends on the downstream task and the available data. However, it is definitely worth to experiment with Data Fusion, as it may provide significant performance benefits.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iW4h3fJkJ6ia"
      },
      "source": [
        "## What's next?\n",
        "\n",
        "We will introduce Multitask Learning next and discuss Self-supervised Learning afterwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hM08ILN_KJs-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "6e741a586f6b68b554925f4bea211b6852c45fbf3b1f1159871bb4b38b6bf4de"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
